
# This file manages conversation history for each user and from the bot to the user (2 ways).
# Store conversations in memory (simple dictionary for now)

from configs.assistant_profile import build_default_system_prompt

_conversations = {}

def init_conversation(user_id:int,bot_name:str="Luna")->list:
    #Initialize conversation history for a new user
    if user_id not in _conversations:
        _conversations[user_id] = [
            {"role": "system", "content": build_default_system_prompt(bot_name)}
        ]
    return _conversations[user_id]

MAX_HISTORY_LENGTH = 50

async def check_and_summarize_if_needed(user_id: int):
    history = get_conversation(user_id)
    if len(history) > MAX_HISTORY_LENGTH:
        try:
            from services.openai_client import summarize_conversation
            summary = await summarize_conversation(history[1:])  # exclude system message
            _conversations[user_id] = [
                history[0],  # system prompt
                {"role": "assistant", "content": f"Summary of earlier conversation:\n{summary}"}
            ]
        except Exception as e:
            print(f"Summarization failed: {e}")

def get_conversation(user_id: int) -> list:
   #Return full message history (including system prompt)
    return _conversations.get(user_id) or init_conversation(user_id)

async def append_user_message(user_id: int, message: str):
    init_conversation(user_id)
    _conversations[user_id].append({"role": "user", "content": message})
    await check_and_summarize_if_needed(user_id)

def append_bot_message(user_id: int, message: str):
    """
    Appends the assistant's message to the conversation history (with role "assistant").

    Args:
        user_id (int): Telegram user ID
        message (str): The bot's response
    """
    init_conversation(user_id)
    _conversations[user_id].append({"role": "assistant", "content": message})

def clear_conversation(user_id: int):
#Wipe conversation (e.g. on /reset command).
    if user_id in _conversations:
        del _conversations[user_id]

def export_conversation(user_id: int) -> list:
    #Return a copy of the conversation (for logging/debugging).
    return list(_conversations.get(user_id, []))



# ðŸ§  Conversation Memory (In-Memory "DB")

# Each user is identified by their unique user_id, and their conversation is saved as a list of messages, following OpenAIâ€™s expected structure:
# _conversations[user_id] = [
#     {"role": "system", "content": "You are Luna, a smart home assistant..."},
#     {"role": "user", "content": "Turn off the kitchen light"},
#     {"role": "assistant", "content": "âœ… Kitchen light turned off."}
# ]
# The role field indicates who sent the message:

# system: Defines Lunaâ€™s personality and abilities
# user: A message from the human user
# assistant: A response generated by ChatGPT

# This memory is used to send full conversation context to GPT on every request.
# It ensures Luna stays in character and remembers what was said earlier in the session.

